}
#bangdiwala.fn: Bangdiwala's B coefficient (see Shankar & Bangdiwala, 2014) and its standard error for 2 raters when input dataset is a contingency table
#-------------
#The input data "ratings" is a qxq contingency table showing the distribution of
#subjects by rater, when q is the number of categories.
#======================================================================================
#' Bangdiwala B coefficient for 2 raters
#' @param ratings A square table of ratings (assume no missing ratings).
#' @param weights An optional matrix that contains the weights used in the weighted analysis. By default, this parameter contaings the identity weight matrix, which leads to the unweighted analysis.
#' @param conflev An optional parameter that specifies the confidence level used for constructing confidence intervals. By default the function assumes the standard value of 95\%.
#' @param N An optional parameter representing the finite population size if any. It is used to perform the finite population correction to the standard error. It's default value is infinity.
#' @return A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
#' @examples
#' #The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
#' bangdiwala.fn(cont3x3abstractors) #Yields Scott's Pi coefficient along with precision measures
#' Bcoeff <- bangdiwala.fn(cont3x3abstractors)$coeff.val #Yields Scott's coefficient alone.
#' Bcoeff
#' q <- nrow(cont3x3abstractors) #Number of categories
#' @export
bangdiwala.table <- function(ratings,conflev=0.95,N=Inf){
ratings <- as.matrix(ratings)
if(dim(ratings)[1] != dim(ratings)[2]){
stop('The contingency table should have the same number of rows and columns!')
}
n <- sum(ratings) # number of subjects
f <- n/N # finite population correction
q <- ncol(ratings) # number of categories
pk. <- rowSums(ratings)/n
p.k <- colSums(ratings)/n
b1 <- sum((diag(ratings)/n)**2)
b2 <- c(pk.%*%p.k)
bcoeff <- as.vector(b1/b2) # Bangdiwala B coefficient
# Variance of Bangdiwala's B coefficient
pi.k <- (pk.+p.k)/2
pkl = ratings/n
pkk <- diag(ratings)/n
var1 = 2*sum((pkk^2)*(pkk-2*bcoeff*pi.k))
var2 = (bcoeff^2)*sum(pi.k*pk.*p.k + (pkl%*%pk.)*p.k)
var = 2*(var1+var2)/(n*(b2^2))
varB <- (1-f)*var
varB <- max(varB,1e-100)
stderr <- sqrt(varB)  #standard error
p.value <- NA;lcb <- NA;ucb <- NA
if (n>=2){
p.value <- 1-pt(bcoeff/stderr,n-1)
lcb <- bcoeff - stderr*qt(1-(1-conflev)/2,n-1) # lower confidence bound
ucb <- min(1,bcoeff + stderr*qt(1-(1-conflev)/2,n-1)) # upper confidence bound
}
conf.int <- paste0("(",round(lcb,3),",",round(ucb,3),")")
coeff.name <- "Bangdiwala's B"
coeff.val <- bcoeff
coeff.se <- stderr
coeff.ci <- conf.int
coeff.pval <- format(p.value,digits=4,nsmall=3,scientific = TRUE)
return(data.frame(coeff.name,coeff.val,coeff.se,coeff.ci,coeff.pval))
}
#pa2.table: Percent agreement coefficient and its standard error for 2 raters when input dataset is a contingency table
#-------------
#The input data "ratings" is a qxq contingency table showing the distribution of
#subjects by rater, when q is the number of categories.
#======================================================================================
#' Percent Agreement coefficient for 2 raters
#' @param ratings A square table of ratings (assume no missing ratings).
#' @param weights An optional matrix that contains the weights used in the weighted analysis. By default, this
#' parameter contains the identity weight matrix, which leads to the unweighted analysis.
#' @param conflev An optional parameter that specifies the confidence level used for constructing confidence
#' intervals. By default the function assumes the standard value of 95\%.
#' @param N An optional parameter representing the finite population size if any. It is used to perform the finite
#' population correction to the standard error. It's default value is infinity.
#' @return A data frame containing the following 5 variables: coeff.name coeff.val coeff.se coeff.ci coeff.pval.
#' @examples
#' #The dataset "cont3x3abstractors" comes with this package. Analyze it as follows:
#' pa2.table(cont3x3abstractors) #Yields percent agreement along with precision measures
#' pa <- pa2.table(cont3x3abstractors)$coeff.val #Yields percent agreement alone.
#' pa
#' q <- nrow(cont3x3abstractors) #Number of categories
#' pa2.table(cont3x3abstractors,weights = quadratic.weights(1:q)) #Weighted percent agreement
#' @export
pa2.table <- function(ratings,weights=identity.weights(1:ncol(ratings)),conflev=0.95,N=Inf){
ratings <- as.matrix(ratings)
if(dim(ratings)[1] != dim(ratings)[2]){
stop('The contingency table should have the same number of rows and columns!')
}
if (ncol(ratings) != ncol(weights)){
stop('The weight matrix has fewer columns than the contingency table. Please revise your input weights!')
}
n <- sum(ratings) # number of subjects
f <- n/N # finite population correction
q <- ncol(ratings) # number of categories
pa <- sum(weights * ratings/n) # percent agreement
# calculation of variance - standard error - confidence interval - p-value
pkl <- ratings/n	     #p_{kl}
sum1 <- 0
for(k in 1:q){
for(l in 1:q){
sum1 <- sum1 + pkl[k,l] * weights[k,l]^2
}
}
var.pa <- ((1-f)/n) * (sum1 - pa^2)
var.pa <- max(var.pa,1e-100)
stderr <- sqrt(var.pa) # pa standard error
p.value <- NA;lcb <- NA;ucb <- NA
if (n>=2){
p.value <- 1-pt(pa/stderr,n-1)
lcb <- pa - stderr*qt(1-(1-conflev)/2,n-1) # lower confidence bound
ucb <- min(1,pa + stderr*qt(1-(1-conflev)/2,n-1)) # upper confidence bound
}
conf.int <- paste0("(",round(lcb,3),",",round(ucb,3),")")
coeff.name <- "Percent Agreement"
coeff.val <- pa
coeff.se <- stderr
coeff.ci <- conf.int
coeff.pval <- format(p.value,digits=4,nsmall=3,scientific = TRUE)
return(data.frame(coeff.name,coeff.val,coeff.se,coeff.ci,coeff.pval))
}
pa2.table(win.mat)
source("~/Cloud Computing/RpackagesWork/irrCAC/R/weights.gen.r", echo=TRUE)
#' Function for computing the Identity Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of identity weights to be used for calculating the unweighted coefficients.
#' @export
identity.weights<-function(categ){
weights<-diag(length(categ))
return (weights)
}
#' Function for computing the Quadratic Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of quadratic weights to be used for calculating the weighted coefficients.
#' @export
quadratic.weights<-function(categ){
q<-length(categ)
weights <- diag(q)
if (is.numeric(categ)) {
categ.vec <- sort(categ)
}
else {
categ.vec<-1:length(categ)
}
xmin<-min(categ.vec)
xmax<-max(categ.vec)
if (q==1) weights[1,1] <- 1
else{
for(k in 1:q){
for(l in 1:q){
weights[k,l] <- 1-(categ.vec[k]-categ.vec[l])^2/(xmax-xmin)^2
}
}
}
return (weights)
}
#' Function for computing the Linear Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of quadratic weights to be used for calculating the weighted coefficients.
#' @export
linear.weights<-function(categ){
q<-length(categ)
weights <- diag(q)
if (is.numeric(categ)) {
categ.vec <- sort(categ)
}
else {
categ.vec<-1:length(categ)
}
xmin<-min(categ.vec)
xmax<-max(categ.vec)
if (q==1) weights[1,1] <- 1
else{
for(k in 1:q){
for(l in 1:q){
weights[k,l] <- 1-abs(categ.vec[k]-categ.vec[l])/abs(xmax-xmin)
}
}
}
return (weights)
}
#--------------------------------
#' Function for computing the Radical Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of quadratic weights to be used for calculating the weighted coefficients.
#' @export
radical.weights<-function(categ){
q<-length(categ)
weights <- diag(q)
if (is.numeric(categ)) {
categ.vec <- sort(categ)
}
else {
categ.vec<-1:length(categ)
}
xmin<-min(categ.vec)
xmax<-max(categ.vec)
if (q==1) weights[1,1] <- 1
else{
for(k in 1:q){
for(l in 1:q){
weights[k,l] <- 1-sqrt(abs(categ.vec[k]-categ.vec[l]))/sqrt(abs(xmax-xmin))
}
}
}
return (weights)
}
#--------------------------------
#' Function for computing the Ratio Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of quadratic weights to be used for calculating the weighted coefficients.
#' @export
ratio.weights<-function(categ){
q<-length(categ)
weights <- diag(q)
if (is.numeric(categ)) {
categ.vec <- sort(categ)
}
else {
categ.vec<-1:length(categ)
}
xmin<-min(categ.vec)
xmax<-max(categ.vec)
if (q==1) weights[1,1] <- 1
else{
for(k in 1:q){
for(l in 1:q){
weights[k,l] <- 1-((categ.vec[k]-categ.vec[l])/(categ.vec[k]+categ.vec[l]))^2 / ((xmax-xmin)/(xmax+xmin))^2
}
}
}
return (weights)
}
#--------------------------------
#' Function for computing the Circular Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of quadratic weights to be used for calculating the weighted coefficients.
#' @export
circular.weights<-function(categ){
q<-length(categ)
weights <- diag(q)
if (is.numeric(categ)) {
categ.vec <- sort(categ)
}
else {
categ.vec<-1:length(categ)
}
xmin<-min(categ.vec)
xmax<-max(categ.vec)
U = xmax-xmin+1
if (q==1) weights[1,1] <- 1
else{
for(k in 1:q){
for(l in 1:q){
weights[k,l] <- (sin(pi*(categ.vec[k]-categ.vec[l])/U))^2
}
}
weights <- 1-weights/max(weights)
}
return (weights)
}
#--------------------------------
#' Function for computing the Bipolar Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of quadratic weights to be used for calculating the weighted coefficients.
#' @export
bipolar.weights<-function(categ){
q<-length(categ)
weights <- diag(q)
if (is.numeric(categ)) {
categ.vec <- sort(categ)
}
else {
categ.vec<-1:length(categ)
}
xmin<-min(categ.vec)
xmax<-max(categ.vec)
if (q==1) weights[1,1] <- 1
else{
for(k in 1:q){
for(l in 1:q){
if (k!=l)
weights[k,l] <- (categ.vec[k]-categ.vec[l])^2 / (((categ.vec[k]+categ.vec[l])-2*xmin)*(2*xmax-(categ.vec[k]+categ.vec[l])))
else weights[k,l] <- 0
}
}
weights <- 1-weights/max(weights)
}
return (weights)
}
#--------------------------------
#' Function for computing the Ordinal Weights
#' @param  categ A mandatory parameter representing the vector of all possible ratings.
#' @return A square matrix of quadratic weights to be used for calculating the weighted coefficients.
#' @export
ordinal.weights<-function(categ){
q<-length(categ)
weights <- diag(q)
categ.vec<-1:length(categ)
if (q==1) weights[1,1] <- 1
else{
for(k in 1:q){
for(l in 1:q){
nkl <- max(k,l)-min(k,l)+1
weights[k,l] <- nkl * (nkl-1)/2
}
}
weights <- 1-weights/max(weights)
}
return (weights)
}
pa2.table(win.mat)
bangdiwala.table(win.mat)
a<-load(file="C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\cont3x3abstractors.RData")
a
load(file="C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\cont3x3abstractors.RData")
load("~/Cloud Computing/RpackagesWork/irrCAC/data/cont3x3abstractors.RData")
cont3x3abstractors
load("~/Cloud Computing/RpackagesWork/irrCAC/data/cont4x4diagnosis.RData")
load("C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\cont3x3abstractors.RData")
load("C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\cont3x3abstractors.RData")
load("C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\cac.raw4raters.RData")
a<-load("C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\cac.raw4raters.RData")
a
bangdiwala.table(cont3x3abstractors)
library(irrCAC)
devtools::load_all(".")
devtools::load_all(".")
library(irrCAC)
detach("package:irrCAC", unload = TRUE)
library(irrCAC)
roxygen2::roxygenise()
library(irrCAC)
document()
devtools::document()
roxygen2::roxygenise()
library(irrCAC)
cont3x3abstractors
freqs
fleiss
library(irrCAC)
data()
cont3x3abstractors
freq.tab
devtools::load_all(".")
load(file="C:\Users\GWET-ASUS-14\Documents\Cloud Computing\RpackagesWork\irrCAC\data\freqs.RData")
load(file="C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\freqs.RData")
library(irrCAC)
freq.tab
devtools::document()
library(irrCAC)
freqs.data
?freqs.data
raw2square.fn(freqs.data)
library(irrCAC)
raw2square.fn(freqs.data)
devtools::document()
library(irrCAC)
freqs.data
freq.supp.fn(freqs.data,c("a","b","c","d","e"))
library(tidyverse)
freq.supp.fn(freqs.data,c("a","b","c","d","e"))
a<-freq.supp.fn(freqs.data,c("a","b","c","d","e"))
a
raw2square.fn(freqs.data)
freqs.data
a<-freqs.data
a
a%>%mutate(nn=as.character(colnames(a)[3]))
a%>%mutate(nn=as.character(a[[3]]))
a<-freqs.data
a
dfra.mat <- pivot_wider(data=a,names_from = colnames(a)[2],
values_from = colnames(a)[3],values_fill = 0)
dfra.mat
devtools::document()
library(irrCAC)
raw2square.fn(freqs.data)
raw2square.fn(freqs.data)
freqs.data
raw2square.fn(freqs.data)
freqs.data
freq.supp.fn(freqs.data,c("a","b","c","d","e"))
devtools::document()
library(irrCAC)
raw2square.fn(freqs.data)
raw2square.fn(freqs.data)
devtools::document()
library(irrCAC)
raw2square.fn(freqs.data)
raw2square.fn(freqs.data)
devtools::document()
library(irrCAC)
raw2square.fn(freqs.data)
count(freqs.data[1],freqs.data[2])
freqs.data
count(freqs.data,freqs.data[1],freqs.data[2])
devtools::document()
library(irrCAC)
raw2square.fn(freqs.data)
raw2square.fn(freqs.data)
devtools::document()
library(irrCAC)
raw2square.fn(freqs.data)
freq.supp.fn(freqs.data,c("a","b","c","d","e"))
devtools::document()
library(irrCAC)
devtools::document()
devtools::document()
library(irrCAC)
devtools::document()
library(irrCAC)
bangdiwala.table(long2wide.fn(freqs.data))
?pca
?PCA
devtools::document()
library(irrCAC)
devtools::document()
library(irrCAC)
devtools::document()
library(irrCAC)
load(file="C:\Users\GWET-ASUS-14\Documents\Cloud Computing\RpackagesWork\irrCAC\data\cac.ben.gerry.RData")
load(file="C:\\Users\\GWET-ASUS-14\\Documents\\Cloud Computing\\RpackagesWork\\irrCAC\\data\\cac.ben.gerry.RData")
cac.ben.gerry
devtools::document()
library(irrCAC)
cac.ben.gerry
cac.ben.gerry[,c(3,4)]
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
library(tidyverse)
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
a<-bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
a
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
library(irrCAC)
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
library(irrCAC)
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
library(irrCAC)
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
library(tidyverse)
bangdiwala2RR.table(cac.ben.gerry[,c(3,4)])
library(irrCAC)
library(irrCAC)
ax<-cac.ben.gerry
count(ax,ax[,c(3,4)])
ax[ax==''] <- NA_character_
ax
count(ax,ax[,c(3,4)])
count(ax,ax[,c(3,4)]) %>% drop_na()
count(ax,ax[1],ax[2]) %>% drop_na()
ax<-ax[,c(3,4)]
count(ax,ax[1],ax[2]) %>% drop_na()
library(irrCAC)
ax<-cac.ben.gerry
ax
ax<-ax[,c(3,4)]
ax
bangdiwala2RR.table(ax)
ax
as_tibble(ax)
library(irrCAC)
bangdiwala2RR.table(ax)
ax
ax1<-ax
ax1[ax1=='']<-NA
ax1
count(ax1,ax1[1],ax2[2])
count(ax1,ax1[1],ax1[2])
ax1%>%count(ax1[1],ax1[2])
ax1%>%count(ax1[1],ax1[2])%>%drop_na()
bangdiwala2RR.table(ax)
ax1<-ax
ax1[ax1=='']<-NA_character_
ax1
xx1<-ax1%>%count(ax1[1],ax1[2])
xx1
xx1<-ax1%>%count(ax1[1],ax1[2])%>%drop_na()
xx1
library(irrCAC)
bangdiwala2RR.table(ax)
library(irrCAC)
bangdiwala2RR.table(ax)
library(irrCAC)
bangdiwala2RR.table(ax)
library(irrCAC)
bangdiwala2RR.table(ax)
library(irrCAC)
bangdiwala2RR.table(ax)
library(irrCAC)
bangdiwala2RR.table(ax)
library(irrCAC)
bangdiwala2RR.table(ax)
unique(c(ax1[[1]],ax1[[2]]))
as.vector(unique(c(ax1[[1]],ax1[[2]])))
c(ax1[[1]],ax1[[2]])
ax1[[1]]
ax1[1]
ax1[[1]]
library(irrCAC)
bangdiwala2RR.table(ax)
cac.ben.gerry
cac.ben.gerry[,c(3,4)]
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(irrCAC)
devtools::document()
library(irrCAC)
devtools::document()
library(irrCAC)
